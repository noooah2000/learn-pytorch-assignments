{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noooah2000/learn-pytorch-assignments/blob/main/Custom_datasets_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04. PyTorch Custom Datasets Exercises Template"
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "GaeYzOTLwWh2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Setup the random seed\n",
        "RANDOM_SEED = 42"
      ],
      "metadata": {
        "id": "DNwZLMbCzJLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 取得資料\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "data_path = Path('data')\n",
        "image_path = data_path / 'pizza_steak_sushi'\n",
        "zip_path = data_path / 'pizza_steak_sushi.zip'\n",
        "\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} is exists\")\n",
        "else:\n",
        "  print(f\"Creating {image_path} now\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  with open(zip_path, 'wb') as f:\n",
        "    request = requests.get('https://github.com/mrdbourke/pytorch-deep-learning/raw/refs/heads/main/data/pizza_steak_sushi.zip')\n",
        "    print('Downloading the zip files of images ...')\n",
        "    f.write(request.content)\n",
        "\n",
        "  with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
        "    print('Unzipping the zip file ... ')\n",
        "    zipf.extractall(image_path)\n"
      ],
      "metadata": {
        "id": "MZkCPJBR3lw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定資料路徑\n",
        "train_dir = image_path / 'train'\n",
        "test_dir = image_path / 'test'\n",
        "print(train_dir)\n",
        "print(test_dir)"
      ],
      "metadata": {
        "id": "3A9ZmOn-7Jhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 印出來看看\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "image_path_list = list(image_path.rglob(\"*.jpg\"))\n",
        "random_image_path = random.choice(image_path_list)\n",
        "image_class = random_image_path.parent.stem\n",
        "img = Image.open(random_image_path)\n",
        "print(f\"Random image path: {random_image_path}\")\n",
        "print(f\"Image class: {image_class}\")\n",
        "print(f\"Image height: {img.height}\")\n",
        "print(f\"Image width: {img.width}\")\n",
        "img\n"
      ],
      "metadata": {
        "id": "51ywNKkN7WOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 用matplotlib印出來\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_array = np.asarray(img)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(img_array)\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "Qe4LoASC9sQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset的helper function\n",
        "import os\n",
        "\n",
        "def FindClasses(directory):\n",
        "  classes = sorted(entry.name for entry in os.scandir(path=directory) if entry.is_dir())\n",
        "  if not classes:\n",
        "    raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
        "  class_to_idx = {class_name:idx for idx, class_name in enumerate(classes)}\n",
        "  return classes, class_to_idx\n",
        "\n",
        "FindClasses(test_dir)"
      ],
      "metadata": {
        "id": "z8vJxmxAFqw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 設計Custom Dataset(包含訓練資料的資料擴增設計)\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, target_dir, transform, transform_augment=None, augment=False):\n",
        "    self.paths = list(target_dir.rglob('*.jpg'))\n",
        "    self.transform = transform\n",
        "    self.transform_augment = transform_augment\n",
        "    self.augment = augment\n",
        "    self.classes , self.class_to_idx = FindClasses(target_dir)\n",
        "\n",
        "  def load_image(self, index):\n",
        "    image_path = self.paths[index]\n",
        "    return Image.open(image_path)\n",
        "\n",
        "  def __len__(self):\n",
        "    return 2*len(self.paths) if self.augment else len(self.paths)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    if self.augment:\n",
        "      original_index = index % len(self.paths)\n",
        "      is_aug = (index >= len(self.paths))\n",
        "    else:\n",
        "      original_index = index\n",
        "      is_aug = False\n",
        "\n",
        "    class_name = self.paths[original_index].parent.name\n",
        "    class_index = self.class_to_idx[class_name]\n",
        "    img = self.load_image(original_index)\n",
        "\n",
        "    if is_aug:\n",
        "      return self.transform_augment(img), class_index\n",
        "    else:\n",
        "      return self.transform(img), class_index\n"
      ],
      "metadata": {
        "id": "M1mhUgE7LkOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定資料的transform處裡\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([transforms.Resize((224, 224)), ## (224, 224)是由於transfer learning的默認size\n",
        "                                      transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "transform_original = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                         transforms.ToTensor()])\n",
        "\n",
        "test_transform = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                     transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "fOnMuV8iXNR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 實體化Dataset\n",
        "train_dataset = CustomDataset(target_dir=train_dir,\n",
        "                              transform=transform_original,\n",
        "                              transform_augment=train_transform,\n",
        "                              augment=True)\n",
        "\n",
        "test_dataset = CustomDataset(target_dir=test_dir,\n",
        "                             transform=test_transform)\n",
        "\n",
        "train_dataset_original = CustomDataset(target_dir=train_dir,\n",
        "                                       transform=transform_original)\n",
        "class_names = train_dataset.classes\n",
        "\n",
        "test_dataset_labels = torch.tensor([test_dataset[i][1] for i in range(len(test_dataset))])\n",
        "test_dataset_labels"
      ],
      "metadata": {
        "id": "PcPQW3QrZkM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 視覺化有無augmented的差別\n",
        "random_idx_list = random.sample(range(len(train_dataset)), k=9)\n",
        "plt.figure(figsize=(8,8))\n",
        "for i, idx in enumerate(random_idx_list):\n",
        "  image, label = train_dataset[idx]\n",
        "  image = image.permute(1, 2, 0) #imshow()支援pytorch的tensor\n",
        "  augment_status = idx // (len(train_dataset)/2)\n",
        "  status = '(Augmented)' if augment_status else '(Unaugmented)'\n",
        "\n",
        "  plt.subplot(3, 3, i+1)\n",
        "  plt.imshow(image)\n",
        "  plt.title(f\"{class_names[label]}{status}\\n{image.shape}\", size=10, c='brown' if augment_status else 'black')\n",
        "  plt.subplots_adjust(hspace=0.5, wspace=0.2)\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "ow15hcEWwfvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定Dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              num_workers=NUM_WORKERS,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_dataset,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              num_workers=NUM_WORKERS,\n",
        "                              shuffle=False)\n",
        "\n",
        "next(iter(train_dataloader))[0].shape\n"
      ],
      "metadata": {
        "id": "LSgjCfot9eyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定Transfer Learning的模型\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
        "\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.classifier = torch.nn.Sequential(torch.nn.Dropout(p=0.2, inplace=True),\n",
        "                                       torch.nn.Linear(in_features=1280,\n",
        "                                                       out_features=len(class_names), bias=True)\n",
        "                                       ).to(device)"
      ],
      "metadata": {
        "id": "Wb0W99sUrwHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_func: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer):\n",
        "  model.train()\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  for X_train, y_train in tqdm(dataloader, desc='training', leave=False):\n",
        "    X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "\n",
        "    y_logits = model(X_train)\n",
        "    y_labels = torch.argmax(torch.softmax(y_logits, dim=1), dim=1)\n",
        "\n",
        "    loss = loss_func(y_logits, y_train)\n",
        "    train_loss += loss\n",
        "    acc = (y_labels==y_train).sum().item() / len(y_labels)\n",
        "    train_acc += acc\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "  return train_loss, train_acc"
      ],
      "metadata": {
        "id": "rnUox1qayDes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_func: torch.nn.Module):\n",
        "  model.eval()\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in tqdm(dataloader, desc='testing', leave=False):\n",
        "      X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "      y_logits = model(X_test)\n",
        "      y_labels = torch.argmax(torch.softmax(y_logits, dim=1), dim=1)\n",
        "\n",
        "      loss = loss_func(y_logits, y_test)\n",
        "      test_loss += loss\n",
        "      acc = (y_labels==y_test).sum().item() / len(y_labels)\n",
        "      test_acc += acc\n",
        "\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc\n"
      ],
      "metadata": {
        "id": "O7_EVPpHNKUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_func: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5):\n",
        "  results = {\"train_loss\": [],\n",
        "             \"train_acc\": [],\n",
        "             \"test_loss\": [],\n",
        "             \"test_acc\": []}\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model,\n",
        "                                       dataloader=train_dataloader,\n",
        "                                       loss_func=loss_func,\n",
        "                                       optimizer=optimizer)\n",
        "    test_loss, test_acc = test_step(model=model,\n",
        "                                    dataloader=test_dataloader,\n",
        "                                    loss_func=loss_func)\n",
        "\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    train_acc, test_acc = train_acc*100, test_acc*100\n",
        "    print(f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f}% | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}%\"\n",
        "    )\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "zXxTIh9tOh68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 5 epochs\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(),\n",
        "                             lr=0.001)\n",
        "\n",
        "NUM_EPOCHS = 5\n",
        "model_results = train(model=model,\n",
        "                        train_dataloader=train_dataloader,\n",
        "                        test_dataloader=test_dataloader,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_func=loss_func,\n",
        "                        epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "id": "rV7s2qtIyDIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 預測函數\n",
        "def MakePredictions(model, some_sample_in_test_data, device):\n",
        "  pred_label_list = []\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in some_sample_in_test_data:\n",
        "      sample = torch.unsqueeze(sample, dim=0) #因為模型只吃(batch_size,C,H,W)的input，但sample沒有batch這個維度\n",
        "      pred_logit = model(sample.to(device))\n",
        "      pred_label = torch.argmax(pred_logit, dim=1)\n",
        "      pred_label_list.append(pred_label.cpu())\n",
        "  return torch.cat(pred_label_list) #把list合併成一個tensor"
      ],
      "metadata": {
        "id": "F6Ebq23PhQ_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from random import sample, seed\n",
        "#random.seed(42)\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_dataset), k=16):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "test_samples[0].shape ,test_labels"
      ],
      "metadata": {
        "id": "Nt1FzIF7hijV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 視覺化預測結果\n",
        "pred_labels = MakePredictions(model=model,\n",
        "                              some_sample_in_test_data=test_samples,\n",
        "                              device=device)\n",
        "\n",
        "plt.figure(figsize=(9, 9))\n",
        "row, col = 4, 4\n",
        "for idx, sample in enumerate(test_samples):\n",
        "  plt.subplot(row, col, idx+1)\n",
        "  plt.imshow(sample.permute(1, 2, 0).numpy())\n",
        "  pred_label = pred_labels[idx]\n",
        "  truth_label = test_labels[idx]\n",
        "  title_text = f\"Pred: {class_names[pred_label]} | Truth: {class_names[truth_label]}\"\n",
        "  plt.title(title_text, fontsize=10, c='g' if pred_label == truth_label else 'r')\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "tFk-SLoGhioe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 測試資料預測的結果\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  y_preds = torch.tensor([], dtype=torch.int32)\n",
        "  for a_batch_of_X, _ in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
        "    a_batch_of_y_preds = MakePredictions(model=model,\n",
        "                            some_sample_in_test_data=a_batch_of_X,\n",
        "                            device=device)\n",
        "\n",
        "    y_preds = torch.cat((y_preds, a_batch_of_y_preds), dim=0)\n",
        "print(y_preds[:100])"
      ],
      "metadata": {
        "id": "-pL_4nO2BBR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import torchmetrics, mlxtend\n",
        "except:\n",
        "  !pip install -q torchmetrics -U mlxtend\n",
        "  import torchmetrics, mlxtend\n",
        "print(f\"mlxtend version: {mlxtend.__version__}\")"
      ],
      "metadata": {
        "id": "qJMdi0ahAd_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 用Confusion Matrix分析模型精準度\n",
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "confmat = ConfusionMatrix(num_classes=len(class_names),\n",
        "                          task='multiclass')\n",
        "confmat_tensor = confmat(preds=y_preds,\n",
        "                         target=test_dataset_labels)\n",
        "plot_confusion_matrix(conf_mat=confmat_tensor.numpy(),\n",
        "                      class_names=class_names,\n",
        "                      figsize=(10, 7))\n",
        "for idx in range(len(class_names)):\n",
        "  count = torch.sum((y_preds == idx)&(test_dataset_labels == idx))\n",
        "  print(f\"Count of correct predictions for class [{class_names[idx]}]: {count}\")"
      ],
      "metadata": {
        "id": "E2G0nBs5Ajcz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}